#!/usr/bin/env python3

#
# TODO: refactor this and the gen-atlas script (copypasta, spaghetti code)
#

import rectpack
import argparse
import shutil
import subprocess
import re
import freetype as ft
import rectpack
import io
import sys
import struct
import ctypes

from pathlib import (
    Path,
)

from tempfile import (
    TemporaryDirectory,
)

from contextlib import (
    ExitStack,
)

from concurrent.futures import (
    ThreadPoolExecutor,
    as_completed,
)

from collections import (
    namedtuple,
)

from heapq import (
    heappush,
)

from PIL import (
    Image,
)

from taiseilib.common import (
    run_main,
    update_text_file,
    TaiseiError,
)


def make_glyph_image(face, glyph_id):
    # face.load_glyph(glyph_id, ft.FT_LOAD_RENDER | ft.FT_LOAD_MONOCHROME)
    bitmap = face.glyph.bitmap

    if not bitmap.buffer:
        return None

    return Image.frombytes('L', (bitmap.width, bitmap.rows), bytes(bitmap.buffer))


def fixed_ceil(x):
    return (((x + 63) & -64) // 64)


def fixed_floor(x):
    return ((x & -64) // 64)


fixed_mul = ft.FT_MulFix


def write_texture_def(dst, texture, global_overrides=None, local_overrides=None):
    dst.parent.mkdir(exist_ok=True, parents=True)

    text = (
        '# Autogenerated by the font generator, do not modify\n\n'
        'source = res/gfx/{texture}.png\n'
    ).format(texture=texture)

    if global_overrides is not None:
        text += '\n# -- Pasted from the global override file --\n\n{}\n'.format(global_overrides.strip())

    if local_overrides is not None:
        text += '\n# -- Pasted from the local override file --\n\n{}\n'.format(local_overrides.strip())

    update_text_file(dst, text)


def format_glyph_def(codepoint, metrics, texcoords, kernings=None):
    print(codepoint, metrics, texcoords)

    lines = [
        '@glyph = 0x{codepoint:08X}',
        'bearing_x = {metrics[bearing_x]:g}',
        'bearing_y = {metrics[bearing_y]:g}',
        'advance = {metrics[advance]:g}',
        'width = {metrics[width]:g}',
        'height = {metrics[height]:g}',
    ]

    if texcoords:
        lines += [
            'page = {texcoords[0]}',
            'texregion_x = {texcoords[1]}',
            'texregion_y = {texcoords[2]}',
            'texregion_width = {texcoords[3]}',
            'texregion_height = {texcoords[4]}',
        ]

    for other_codepoint in sorted(kernings or {}):
        kerning = kernings[other_codepoint]
        lines.append('kern 0x{codepoint:08X} = {kerning}'.format(
            codepoint=other_codepoint,
            kerning=kernings[other_codepoint]
        ))

    return '\n'.join(lines).format(codepoint=codepoint, metrics=metrics, texcoords=texcoords)


def format_page_name(fontname, pagenum):
    return 'fontatlas_{}_{}'.format(fontname, pagenum)


def write_font_def(params, dst, properties, codepoints, metrics, texcoords, kernings=None):
    with io.StringIO() as stream:
        stream.write('\n'.join((
            '# Autogenerated by the font generator, do not modify\n',
            'ascender = {ascender:g}',
            'descender = {descender:g}',
            'lineskip = {lineskip:g}',
            'texture_scale = {texture_scale}',
            'num_glyphs = {num_glyphs}',
            'num_pages = {num_pages}',
        )).format(**properties))

        for i in range(properties['num_pages']):
            stream.write('\npage {} = {}'.format(i, format_page_name(params.name, i)))

        stream.write('\n\n')

        for cp in codepoints:
            stream.write(format_glyph_def(
                cp,
                metrics[cp],
                texcoords.get(cp),
                kernings.get(cp) if kernings else None
            ) + '\n\n')

        update_text_file(dst, stream.getvalue())


def load_kern_table(face):
    table = {}
    length = ft.FT_ULong(0)
    kern_tag = (ord('k') << 24) | (ord('e') << 16) | (ord('r') << 8) | (ord('n'))
    error = ft.FT_Load_Sfnt_Table(face._FT_Face, kern_tag, 0, 0, ctypes.byref(length))

    if error or not length.value:
        print(error, length)
        return table

    buf = (ctypes.c_char * length.value)()
    error = ft.FT_Load_Sfnt_Table(face._FT_Face, kern_tag, 0, ctypes.byref(buf), ctypes.byref(length))

    if error:
        return table

    with io.BytesIO(buf.raw) as stream:
        def read(fmt):
            return struct.unpack(fmt, stream.read(struct.calcsize(fmt)))

        version, num_tables = read('>HH')

        if version != 0 or num_tables == 0:
            return table

        for i in range(num_tables):
            (
                version,
                length,
                coverage,
            ) = read('>HHH')

            if version != 0 or length == 0 or coverage != 0x1:
                continue

            num_pairs, _, _, _ = read('>HHHH')

            for pair in range(num_pairs):
                left, right, kerning = read('>HHh')
                table.setdefault(left, {})[right] = kerning

    return table


def map_codepoints_to_glyphs(face):
    for codepoint, glyph_id in face.get_chars():
        # Filter non-1-to-1 mappings based on the current charmap
        if glyph_id == ft.FT_Get_Char_Index(face._FT_Face, codepoint):
            yield codepoint, glyph_id
        else:
            print("Glyph {} for codepoint {:08X} discarded".format(glyph_id, codepoint), file=sys.stderr)


def make_font(params):
    face = ft.Face(str(params.src_font))
    ss = params.supersampling * params.sdf_scale

    face.set_char_size((params.size * ss) << 6)

    raw_kern_table = load_kern_table(face)
    converted_kern_table = {}

    global_properties = dict(
        ascender = (face.size.ascender / ss) / 64,
        descender = (face.size.descender / ss) / 64,
        lineskip = (face.size.height / ss) / 64,
        texture_scale = params.sdf_scale,
        num_pages = 0,
        num_glyphs = 0,
    )

    glyph_metrics = {}
    glyph_images = {}
    glyph_tex_coords = {}

    codepoint_to_glyph = {}
    glyph_to_codepoint = {}

    for codepoint, glyph_id in map_codepoints_to_glyphs(face):
        codepoint_to_glyph[codepoint] = glyph_id
        glyph_to_codepoint[glyph_id] = codepoint

    with ExitStack() as stack:
        temp_dir = Path(stack.enter_context(TemporaryDirectory(prefix='taisei-gen-font-{}'.format(params.name))))
        # temp_dir = params.out_texture_dir
        executor = stack.enter_context(ThreadPoolExecutor())

        for codepoint, glyph_id in codepoint_to_glyph.items():
            face.load_glyph(glyph_id, ft.FT_LOAD_RENDER)
            img = make_glyph_image(face, glyph_id)

            glyph_metrics[codepoint] = dict(
                bearing_x = (face.glyph.metrics.horiBearingX / ss) / 64,
                bearing_y = (face.glyph.metrics.horiBearingY / ss) / 64,
                advance   = (face.glyph.metrics.horiAdvance / ss) / 64,
                width     = (face.glyph.metrics.width / ss) / 64,
                height    = (face.glyph.metrics.height / ss) / 64,
            )

            if img is None:
                continue

            path = temp_dir / (hex(codepoint) + '.png')
            print(path)
            img.save(path)
            img.close()
            glyph_images[codepoint] = path

        for left_codepoint, left_glyph_id in codepoint_to_glyph.items():
            try:
                raw_ltable = raw_kern_table[left_glyph_id]
            except KeyError:
                continue

            for right_glyph_id in raw_ltable:
                kerning = raw_ltable[right_glyph_id]
                kerning = (ft.FT_MulFix(kerning, face.size.x_scale) / ss) / 64

                if kerning != 0:
                    right_codepoint = glyph_to_codepoint[right_glyph_id]
                    converted_kern_table.setdefault(left_codepoint, {})[right_codepoint] = kerning

        def process_glyph(codepoint, glyph_id):
            img_in_path = glyph_images.get(codepoint)

            if img_in_path is None:
                return codepoint, None

            suffix = img_in_path.suffix
            # img_out_path = img_in_path.with_name('%s_sdf%s' % (img_in_path.stem, suffix))
            img_out_path = img_in_path

            #
            #   And thus, I declare my ultimate Spell Card! Behold!
            #
            #   ~ Signed Distance Field 「Boundary of Raster and Vector」 ~
            #

            incantation = [
                'convert',
                img_in_path.resolve(),
                '-verbose',
                '-trim',
                '-background', 'black',
                '-gravity', 'center',
                '-extent', '400%,400%',
                '-negate',
                '-alpha', 'off',
                '-threshold', '50%',
                '+depth',
                '(',
                    '+clone',
                    '-negate',
                    '-morphology', 'Distance', 'Euclidean',
                    '-level', '50%,-50%',
                ')',
                '-morphology', 'Distance', 'Euclidean',
                '-compose', 'Plus',
                '-composite',
                '-level', '45%,55%',
                '-filter', 'Jinc',
                '-resize', '%g%%' % (100 / params.supersampling),
                '-trim',
                '-negate',
                img_out_path.resolve(),
            ]

            subprocess.check_call(incantation)

            return codepoint, img_out_path

        jobs = (
            executor.submit(process_glyph, codepoint, glyph_id)
                for codepoint, glyph_id in codepoint_to_glyph.items()
        )

        # NOTE: No invisible ones here!
        # We sort them by value based on the assumption that close codepoints are
        # more likely to be used together than distant ones.
        sorted_codepoints = []
        invisible_codepoints = []

        for job in as_completed(jobs):
            codepoint, sdf_path = job.result()

            if sdf_path is None:
                invisible_codepoints.append(codepoint)
                continue

            glyph_images[codepoint] = sdf=Image.open(sdf_path)
            heappush(sorted_codepoints, codepoint)

        total_codepoints = len(sorted_codepoints)
        border = params.border
        binsize = (params.page_width, params.page_height)

        packer = rectpack.newPacker(
            # No rotation support in Taisei yet
            rotation=False,

            # Doesn't scale well'
            # pack_algo=rectpack.MaxRectsBl,

            pack_algo=rectpack.SkylineBlWm,
            bin_algo=rectpack.PackingBin.BFF,

            # No sort because we did our own
            sort_algo=rectpack.SORT_NONE,
        )

        for codepoint in sorted_codepoints:
            img = glyph_images[codepoint]
            packer.add_bin(*binsize)
            packer.add_rect(img.size[0] + border * 2, img.size[1] + border * 2, codepoint)

        packer.pack()
        num_packed = sum(len(bin) for bin in packer)

        if num_packed != total_codepoints:
            missing = total_codepoints - num_packed
            raise TaiseiError("{} glyph{} not packed (bin size is too small?)".format(
                missing, "s were" if missing > 1 else " was"
            ))

        atlas_temp_dst = temp_dir / 'atlas'
        atlas_temp_dst.mkdir(exist_ok=True)

        for i, bin in enumerate(packer):
            global_properties['num_pages'] += 1

            texture_name = format_page_name(params.name, i)
            texture_dst_image_path = atlas_temp_dst / '{}.png'.format(texture_name)
            texture_dst_config_path = atlas_temp_dst / '{}.tex'.format(texture_name)

            actual_size = [0, 0]

            if params.crop:
                for rect in bin:
                    if rect.x + rect.width > actual_size[0]:
                        actual_size[0] = rect.x + rect.width

                    if rect.y + rect.height > actual_size[1]:
                        actual_size[1] = rect.y + rect.height
            else:
                actual_size = (bin.width, bin.height)

            write_texture_def(texture_dst_config_path, texture_name)
            texture_img = Image.new('I', tuple(actual_size), 0)

            for rect in bin:
                codepoint = rect.rid
                img = glyph_images[codepoint]

                region = (
                    rect.x + border,
                    rect.y + border,
                    rect.x + rect.width - border,
                    rect.y + rect.height - border
                )

                texture_img.paste(img, region)
                img.close()

                glyph_tex_coords[codepoint] = (
                    i,
                    region[0],
                    region[1],
                    region[2] - region[0],
                    region[3] - region[1]
                )

            print('Atlas texture area: ', texture_img.size[0] * texture_img.size[1])
            texture_img.save(texture_dst_image_path)
            texture_img.close()

        for codepoint in invisible_codepoints:
            heappush(sorted_codepoints, codepoint)

        global_properties['num_glyphs'] = len(sorted_codepoints)
        executor.shutdown(wait=True)

        # Only now, if everything is ok so far, copy everything to the destination, possibly overwriting previous results
        pattern = re.compile('^fontatlas_{}_\d+.png$'.format(re.escape(params.name)))
        for path in params.out_texture_dir.iterdir():
            if pattern.match(path.name):
                path.unlink()

        targets = list(atlas_temp_dst.glob('**/*'))

        for dir in (p.relative_to(atlas_temp_dst) for p in targets if p.is_dir()):
            (params.out_texture_dir / dir).mkdir(parents=True, exist_ok=True)

        for file in (p.relative_to(atlas_temp_dst) for p in targets if not p.is_dir()):
            shutil.copyfile(str(atlas_temp_dst / file), str(params.out_texture_dir / file))

        fontdef_name = '{}.font'.format(params.name)

        write_font_def(
            params,
            params.out_fontdef_dir / fontdef_name,
            global_properties,
            sorted_codepoints,
            glyph_metrics,
            glyph_tex_coords,
            converted_kern_table,
        )


def main(args):
    parser = argparse.ArgumentParser(description='Generate a signed distance field font from a TTF or OTF', prog=args[0])

    parser.add_argument('src_font',
        help='Source TTF or OTF font',
        type=Path,
    )

    parser.add_argument('size',
        help='Base font size in pixels',
        type=int,
    )

    parser.add_argument('name',
        help='Base font name to construct output filenames from',
        type=str,
    )

    parser.add_argument('out_fontdef_dir',
        help='Directory where to save the font definition file',
        type=Path,
    )

    parser.add_argument('out_texture_dir',
        help='Directory where to save the textures',
        type=Path,
    )

    parser.add_argument('--supersampling',
        help='Intermediate resolution multiplier, improves quality but tanks performance (default: 4)',
        type=int,
        default=4,
    )

    parser.add_argument('--sdf-scale',
        help='Size multiplier, affects SDF resolution, but not font metrics (default: 2)',
        type=int,
        default=2,
    )

    parser.add_argument('--border', '-b',
        help='Add a protective border WIDTH pixels wide around each sprite (default: 1)',
        metavar='WIDTH',
        dest='border',
        type=int,
        default=1
    )

    parser.add_argument('--crop', '-c',
        help='Remove unused space from bins (default)',
        dest='crop',
        action='store_true',
        default=True,
    )

    parser.add_argument('--no-crop', '-C',
        help='Do not remove unused space from atlases',
        dest='crop',
        action='store_false',
        default=True,
    )

    parser.add_argument('--page-width', '-W',
        help='Base width of a single atlas bin (default: 2048)',
        default=2048,
        type=int
    )

    parser.add_argument('--page-height', '-H',
        help='Base height of a single atlas bin (default: 2048)',
        default=2048,
        type=int
    )

    make_font(parser.parse_args())

if __name__ == '__main__':
    run_main(main)
